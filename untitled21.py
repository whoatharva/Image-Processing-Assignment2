# -*- coding: utf-8 -*-
"""Untitled21.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13T8mMoQpPd3UfnZ-CNiq3Yv4z5V7sp7V
"""

from google.colab import drive
import numpy as np
import matplotlib.pyplot as plt
import cv2
import os

#drive.mount('/content/drive')

WORKING_DIR = '/content/sample_data'  # Update this path
IMAGE_PATH = os.path.join(WORKING_DIR, 'RGB.jpg')

def load_image_from_drive():
    """
    Loads image from Google Drive.
    Returns the image in RGB format.
    """
    if not os.path.exists(IMAGE_PATH):
        raise FileNotFoundError(f"Image not found at {IMAGE_PATH}")

    # Read image
    image = cv2.imread(IMAGE_PATH)
    if image is None:
        raise ValueError(f"Failed to load image from {IMAGE_PATH}")

    # Convert to RGB
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    print(f"Successfully loaded image from: {IMAGE_PATH}")
    print(f"Image shape: {image.shape}")
    return image

def create_gaussian_kernel(size, sigma):
    """
    Creates a Gaussian kernel of specified size and sigma.

    Args:
        size (int): Kernel size (must be odd)
        sigma (float): Standard deviation of Gaussian distribution

    Returns:
        numpy.ndarray: 2D Gaussian kernel
    """
    # Ensure size is odd
    if size % 2 == 0:
        raise ValueError("Kernel size must be odd")

    # Create coordinate grid
    k = (size - 1) // 2
    x, y = np.meshgrid(np.linspace(-k, k, size), np.linspace(-k, k, size))

    # Calculate Gaussian values
    gaussian = np.exp(-(x**2 + y**2) / (2 * sigma**2))

    # Normalize the kernel
    return gaussian / gaussian.sum()

def custom_convolution(image, kernel):
    """
    Applies convolution operation on an image with given kernel.

    Args:
        image (numpy.ndarray): Input image
        kernel (numpy.ndarray): Convolution kernel

    Returns:
        numpy.ndarray: Convolved image
    """
    # Get image and kernel dimensions
    i_height, i_width, channels = image.shape
    k_height, k_width = kernel.shape

    # Calculate padding
    pad_h = k_height // 2
    pad_w = k_width // 2

    # Create padded image
    padded_image = np.pad(image, ((pad_h, pad_h), (pad_w, pad_w), (0, 0)), mode='edge')

    # Initialize output image
    output = np.zeros_like(image, dtype=np.float32)

    # Apply convolution
    for c in range(channels):
        for i in range(i_height):
            for j in range(i_width):
                # Extract region of interest
                roi = padded_image[i:i+k_height, j:j+k_width, c]
                # Apply kernel
                output[i, j, c] = np.sum(roi * kernel)

    # Normalize output to 0-255 range
    output = np.clip(output, 0, 255).astype(np.uint8)
    return output

def custom_gaussian_blur(image, kernel_size, sigma):
    """
    Applies Gaussian blur to an image.

    Args:
        image (numpy.ndarray): Input image
        kernel_size (int): Size of Gaussian kernel
        sigma (float): Standard deviation for Gaussian kernel

    Returns:
        numpy.ndarray: Blurred image
    """
    kernel = create_gaussian_kernel(kernel_size, sigma)
    return custom_convolution(image, kernel)

def custom_sobel(image):
    """
    Applies Sobel edge detection.

    Args:
        image (numpy.ndarray): Input image

    Returns:
        tuple: Horizontal and vertical edge maps
    """
    # Convert to grayscale if needed
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    else:
        gray = image

    # Sobel kernels
    sobel_x = np.array([[-1, 0, 1],
                        [-2, 0, 2],
                        [-1, 0, 1]])

    sobel_y = np.array([[-1, -2, -1],
                        [0, 0, 0],
                        [1, 2, 1]])

    # Pad image
    padded = np.pad(gray, ((1, 1), (1, 1)), mode='edge')

    # Initialize output
    edges_x = np.zeros_like(gray, dtype=float)
    edges_y = np.zeros_like(gray, dtype=float)

    # Apply convolution
    for i in range(gray.shape[0]):
        for j in range(gray.shape[1]):
            # Extract region
            roi = padded[i:i+3, j:j+3]
            # Calculate gradients
            edges_x[i, j] = np.sum(roi * sobel_x)
            edges_y[i, j] = np.sum(roi * sobel_y)

    return edges_x, edges_y

def custom_laplacian(image):
    """
    Applies Laplacian edge detection.

    Args:
        image (numpy.ndarray): Input image

    Returns:
        numpy.ndarray: Edge map
    """
    # Convert to grayscale if needed
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    else:
        gray = image

    # Laplacian kernel
    kernel = np.array([[0, 1, 0],
                      [1, -4, 1],
                      [0, 1, 0]])

    # Pad image
    padded = np.pad(gray, ((1, 1), (1, 1)), mode='edge')

    # Initialize output
    edges = np.zeros_like(gray, dtype=float)

    # Apply convolution
    for i in range(gray.shape[0]):
        for j in range(gray.shape[1]):
            roi = padded[i:i+3, j:j+3]
            edges[i, j] = np.sum(roi * kernel)

    return edges

def plot_results(original, processed, title):
    """
    Plots original and processed images side by side.
    """
    plt.figure(figsize=(15, 5))

    plt.subplot(121)
    plt.imshow(original)
    plt.title('Original Image')
    plt.axis('off')

    plt.subplot(122)
    plt.imshow(processed, cmap='gray' if len(processed.shape) == 2 else None)
    plt.title(title)
    plt.axis('off')

    plt.tight_layout()
    plt.show()

def save_results(image, filename):
    """
    Saves processed images to Google Drive.
    """
    output_path = os.path.join(WORKING_DIR, 'results', filename)
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    if len(image.shape) == 2:
        # For grayscale images, convert to 3 channels
        image = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_GRAY2BGR)
    else:
        # For RGB images, convert to BGR for saving
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

    cv2.imwrite(output_path, image)
    print(f"Saved result to: {output_path}")

def alpha_blend(image1, image2, alpha=0.5):
    """
    Performs alpha blending of two images.

    Args:
        image1 (numpy.ndarray): First input image
        image2 (numpy.ndarray): Second input image
        alpha (float): Blending factor (0 to 1)

    Returns:
        numpy.ndarray: Blended image
    """
    if image1.shape != image2.shape:
        raise ValueError("Images must have the same dimensions")

    return cv2.addWeighted(image1, alpha, image2, 1-alpha, 0)

def multiply_blend(image1, image2):
    """
    Performs multiplicative blending of two images.

    Args:
        image1 (numpy.ndarray): First input image
        image2 (numpy.ndarray): Second input image

    Returns:
        numpy.ndarray: Blended image
    """
    if image1.shape != image2.shape:
        raise ValueError("Images must have the same dimensions")

    return (image1 * image2)

def screen_blend(image1, image2):
    """
    Performs screen blending of two images.
    Useful for edge detection as it brightens overlapping edges.

    Args:
        image1 (numpy.ndarray): First input image
        image2 (numpy.ndarray): Second input image

    Returns:
        numpy.ndarray: Blended image
    """
    if image1.shape != image2.shape:
        raise ValueError("Images must have the same dimensions")

    return 1 - (1 - image1) * (1 - image2)

def overlay_blend(image1, image2):
    """
    Performs overlay blending of two images.
    Preserves highlights and shadows of the base layer.

    Args:
        image1 (numpy.ndarray): First input image (base layer)
        image2 (numpy.ndarray): Second input image (overlay layer)

    Returns:
        numpy.ndarray: Blended image
    """
    if image1.shape != image2.shape:
        raise ValueError("Images must have the same dimensions")

    mask = image1 >= 0.5
    result = np.zeros_like(image1)

    # Overlay formula for values >= 0.5
    result[mask] = 1 - 2 * (1 - image1[mask]) * (1 - image2[mask])

    # Overlay formula for values < 0.5
    result[~mask] = 2 * image1[~mask] * image2[~mask]

    return result

def gradient_magnitude_blend(edges_x, edges_y):
    """
    Combines horizontal and vertical edge maps using gradient magnitude.

    Args:
        edges_x (numpy.ndarray): Horizontal edge map
        edges_y (numpy.ndarray): Vertical edge map

    Returns:
        numpy.ndarray: Combined edge map
    """
    return np.sqrt(edges_x**2 + edges_y**2)

def adaptive_blend(edges_x, edges_y):
    """
    Performs adaptive blending based on edge strength in each direction.

    Args:
        edges_x (numpy.ndarray): Horizontal edge map
        edges_y (numpy.ndarray): Vertical edge map

    Returns:
        numpy.ndarray: Adaptively blended edge map
    """
    # Calculate local edge strengths
    strength_x = np.abs(edges_x)
    strength_y = np.abs(edges_y)

    # Calculate adaptive weights
    total_strength = strength_x + strength_y
    total_strength[total_strength == 0] = 1  # Avoid division by zero

    weight_x = strength_x / total_strength
    weight_y = strength_y / total_strength

    # Combine edges using adaptive weights
    return weight_x * edges_x + weight_y * edges_y

def directional_blend(edges_x, edges_y, angle_weight=None):
    """
    Blends edges with directional weighting.

    Args:
        edges_x (numpy.ndarray): Horizontal edge map
        edges_y (numpy.ndarray): Vertical edge map
        angle_weight (numpy.ndarray, optional): Custom angle-based weights

    Returns:
        numpy.ndarray: Directionally blended edge map
    """
    # Calculate edge directions
    angles = np.arctan2(edges_y, edges_x)

    if angle_weight is None:
        # Default weight: emphasize diagonal edges
        angle_weight = np.abs(np.sin(2 * angles))

    # Calculate magnitude
    magnitude = np.sqrt(edges_x**2 + edges_y**2)

    # Apply directional weighting
    return magnitude * (1 + angle_weight) / 2

def demo_blending(image):
    """
    Demonstrates various blending techniques on edge detection results.

    Args:
        image (numpy.ndarray): Input image
    """
    # Get Sobel edges
    edges_x, edges_y = custom_sobel(image)

    # Normalize edge maps
    edges_x_norm = np.abs(edges_x) / np.max(np.abs(edges_x))
    edges_y_norm = np.abs(edges_y) / np.max(np.abs(edges_y))

    # 1. Alpha Blending
    alpha_blended = alpha_blend(edges_x_norm, edges_y_norm, 0.5)
    plot_results(edges_x_norm, alpha_blended, 'Alpha Blending (50-50)')
    save_results(alpha_blended, 'blend_alpha.jpg')

    # 2. Multiply Blending
    mult_blended = multiply_blend(edges_x_norm, edges_y_norm)
    plot_results(edges_y_norm, mult_blended, 'Multiply Blending')
    save_results(mult_blended, 'blend_multiply.jpg')

    # 3. Screen Blending
    screen_blended = screen_blend(edges_x_norm, edges_y_norm)
    plot_results(alpha_blended, screen_blended, 'Screen Blending')
    save_results(screen_blended, 'blend_screen.jpg')

    # 4. Overlay Blending
    overlay_blended = overlay_blend(edges_x_norm, edges_y_norm)
    plot_results(screen_blended, overlay_blended, 'Overlay Blending')
    save_results(overlay_blended, 'blend_overlay.jpg')

    # 5. Gradient Magnitude
    magnitude_blended = gradient_magnitude_blend(edges_x_norm, edges_y_norm)
    plot_results(overlay_blended, magnitude_blended, 'Gradient Magnitude')
    save_results(magnitude_blended, 'blend_magnitude.jpg')

    # 6. Adaptive Blending
    adaptive_blended = adaptive_blend(edges_x_norm, edges_y_norm)
    plot_results(magnitude_blended, adaptive_blended, 'Adaptive Blending')
    save_results(adaptive_blended, 'blend_adaptive.jpg')

    # 7. Directional Blending
    directional_blended = directional_blend(edges_x_norm, edges_y_norm)
    plot_results(adaptive_blended, directional_blended, 'Directional Blending')
    save_results(directional_blended, 'blend_directional.jpg')

    # Compare all methods
    plt.figure(figsize=(20, 10))
    methods = {
        'Original X': edges_x_norm,
        'Original Y': edges_y_norm,
        'Alpha': alpha_blended,
        'Multiply': mult_blended,
        'Screen': screen_blended,
        'Overlay': overlay_blended,
        'Magnitude': magnitude_blended,
        'Adaptive': adaptive_blended,
        'Directional': directional_blended
    }

    for i, (name, img) in enumerate(methods.items(), 1):
        plt.subplot(3, 3, i)
        plt.imshow(img, cmap='gray')
        plt.title(name)
        plt.axis('off')

    plt.tight_layout()
    plt.show()

def main():
    """
    Main execution function.
    """
    try:
        # Load image from Drive
        image = load_image_from_drive()

        # Create results directory
        os.makedirs(os.path.join(WORKING_DIR, 'results'), exist_ok=True)

        # 1. Gaussian Blur
        print("\nApplying Gaussian Blur with different parameters...")
        kernel_sizes = [3, 5, 7]
        sigma_values = [1, 10, 50]

        for size in kernel_sizes:
            for sigma in sigma_values:
                print(f"\nProcessing: kernel size = {size}, sigma = {sigma}")

                # Custom implementation
                blurred = custom_gaussian_blur(image, size, sigma)
                plot_results(image, blurred, f'Custom Gaussian Blur (size={size}, σ={sigma})')
                save_results(blurred, f'gaussian_blur_k{size}_s{sigma}.jpg')

                # OpenCV comparison
                cv2_blurred = cv2.GaussianBlur(image, (size, size), sigma)
                plot_results(blurred, cv2_blurred, 'Custom vs OpenCV Gaussian Blur')
                save_results(cv2_blurred, f'opencv_gaussian_k{size}_s{sigma}.jpg')

        # 2. Sobel Edge Detection
        print("\nApplying Sobel Edge Detection...")
        edges_x, edges_y = custom_sobel(image)

        # Normalize edge maps for visualization
        edges_x_norm = np.abs(edges_x) / np.max(np.abs(edges_x))
        edges_y_norm = np.abs(edges_y) / np.max(np.abs(edges_y))
        edges_combined = np.sqrt(edges_x_norm**2 + edges_y_norm**2)

        plot_results(image, edges_x_norm, 'Horizontal Edges (Sobel X)')
        plot_results(image, edges_y_norm, 'Vertical Edges (Sobel Y)')
        plot_results(image, edges_combined, 'Combined Edges (Sobel)')

        save_results(edges_x_norm, 'sobel_x.jpg')
        save_results(edges_y_norm, 'sobel_y.jpg')
        save_results(edges_combined, 'sobel_combined.jpg')

        # OpenCV Sobel comparison
        cv2_edges_x = cv2.Sobel(cv2.cvtColor(image, cv2.COLOR_RGB2GRAY), cv2.CV_64F, 1, 0, ksize=3)
        cv2_edges_y = cv2.Sobel(cv2.cvtColor(image, cv2.COLOR_RGB2GRAY), cv2.CV_64F, 0, 1, ksize=3)
        cv2_edges_x = np.abs(cv2_edges_x) / np.max(np.abs(cv2_edges_x))
        cv2_edges_y = np.abs(cv2_edges_y) / np.max(np.abs(cv2_edges_y))
        cv2_edges_combined = np.sqrt(cv2_edges_x**2 + cv2_edges_y**2)

        plot_results(edges_combined, cv2_edges_combined, 'Custom vs OpenCV Sobel')
        save_results(cv2_edges_combined, 'opencv_sobel.jpg')

        print("\nDemonstrating various blending techniques...")
        demo_blending(image)

        # 3. Laplacian Edge Detection
        print("\nApplying Laplacian Edge Detection...")
        laplacian_edges = custom_laplacian(image)
        laplacian_edges_norm = np.abs(laplacian_edges) / np.max(np.abs(laplacian_edges))
        plot_results(image, laplacian_edges_norm, 'Laplacian Edges')
        save_results(laplacian_edges_norm, 'laplacian.jpg')

        # OpenCV Laplacian comparison
        cv2_laplacian = cv2.Laplacian(cv2.cvtColor(image, cv2.COLOR_RGB2GRAY), cv2.CV_64F)
        cv2_laplacian = np.abs(cv2_laplacian) / np.max(np.abs(cv2_laplacian))
        plot_results(laplacian_edges_norm, cv2_laplacian, 'Custom vs OpenCV Laplacian')
        save_results(cv2_laplacian, 'opencv_laplacian.jpg')

        print("\nProcessing complete! All results have been saved to the 'results' folder.")

    except Exception as e:
        print(f"An error occurred: {str(e)}")

if __name__ == "__main__":
    main()

